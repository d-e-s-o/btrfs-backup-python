# repository.py

#/***************************************************************************
# *   Copyright (C) 2015 Daniel Mueller (deso@posteo.net)                   *
# *                                                                         *
# *   This program is free software: you can redistribute it and/or modify  *
# *   it under the terms of the GNU General Public License as published by  *
# *   the Free Software Foundation, either version 3 of the License, or     *
# *   (at your option) any later version.                                   *
# *                                                                         *
# *   This program is distributed in the hope that it will be useful,       *
# *   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
# *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
# *   GNU General Public License for more details.                          *
# *                                                                         *
# *   You should have received a copy of the GNU General Public License     *
# *   along with this program.  If not, see <http://www.gnu.org/licenses/>. *
# ***************************************************************************/

"""Repository related functionality.

  This program uses the abstraction of a repository to reason about
  which files to transfer in order to create a backup of a btrfs
  subvolume. A repository is a directory that contains or is supposed to
  contain snapshots.
"""

from datetime import (
  datetime,
)
from deso.btrfs.alias import (
  alias,
)
from deso.btrfs.command import (
  deserialize,
  diff,
  show,
  serialize,
  snapshot as mkSnapshot,
  snapshots as listSnapshots,
  sync as syncFs,
)
from deso.execute import (
  execute,
  executeAndRead,
  pipeline,
)
from os import (
  sep,
  uname,
)
from os.path import (
  dirname,
  join,
)
from re import (
  compile as regex,
)


# The time format for the creation time of a snapshot. This format is
# used for deriving time stamps to be included in a snapshot's name.
# An important property this format has to provide is proper sorting:
# When sorting a list of snapshots (each containing a time stamp of this
# format), the most recent snapshot should always be at the end of the
# list after sorting is through. Since we are comparing strings, this
# property has to hold for all possible locales (even if Python does not
# include locales in their sorting, btrfs might, whose sorted output we
# parse).
_TIME_FORMAT = "%Y-%m-%d_%H:%M:%S"
_ANY_STRING = r"."
_NUM_STRING = r"[0-9]"
_NUMS_STRING = r"{nr}+".format(nr=_NUM_STRING)
_PATH_STRING = r"{any}+".format(any=_ANY_STRING)
_FLAG_STRING = r"[A-Z|]+"
# The format of a line as retrieved by executing the command returned by
# the snapshots() function. Each line is expected to be following the
# pattern:
# ID A gen B top level C path PATH
_LIST_STRING = r"^ID {nums} gen ({nums}) top level {nums} path ({path})$"
_LIST_REGEX = regex(_LIST_STRING.format(nums=_NUMS_STRING, path=_PATH_STRING))
# The first line in the output generated by executing the command
# returned by the show() should contain the subvolume path if the
# given directory is a subvolume. However, if it is the root of the
# btrfs file system then it will end in 'is btrfs root'. We need to
# detect this case to determine the btrfs root.
_SHOW_IS_ROOT = "is btrfs root"
# The format of a line as retrieved by executing the command returned by
# the diff() function. Each line is expected to be following the
# pattern:
# inode A file offset B len C disk start D offset E gen F flags FLAGS PATH
# We do not care about the FLAGS values. Apparently, they are always
# uppercase and can be combined via '|' but we do not interpret them.
_DIFF_STRING = (r"^inode {nums} file offset {nums} len {nums} disk start {nums}"
                r" offset {nums} gen {nums} flags {flags} ({path})$")
_DIFF_REGEX = regex(_DIFF_STRING.format(nums=_NUMS_STRING, flags=_FLAG_STRING,
                                        path=_PATH_STRING))
_DIFF_IGNORE = "transid marker"


def _parseListLine(line):
  """Parse a line of output of the command as returned by snapshots()."""
  m = _LIST_REGEX.match(line)
  if not m:
    raise ValueError("Invalid snapshot list: unable to match line \"%s\"" % line)

  gen, path = m.groups()

  result = {}
  result["gen"] = gen
  result["path"] = path
  return result


def _parseDiffLine(line):
  """Parse a line of output for the command as returned by diff()."""
  m = _DIFF_REGEX.match(line)
  if not m:
    raise ValueError("Invalid diff list: unable to match line \"%s\"" % line)

  path, = m.groups()
  return path


def _snapshots(directory):
  """Retrieve a list of snapshots in a directory.

    Note:
      Because of a supposed bug in btrfs' handling of passed in
      directories, the output of this function is *not* necessarily
      limited to subvolumes *below* the given directory. See test case
      testRepositoryListNoSnapshotPresentInSubdir. For that matter,
      usage of this function is discouraged. Use the Repository's
      snapshots() method instead.
  """
  output = executeAndRead(*listSnapshots(directory))
  # We might retrieve an empty output if no snapshots were present. In
  # this case, just return early here.
  if not output:
    return []

  # Convert from byte array and split to retrieve a list of lines.
  output = output.decode("utf-8").splitlines()
  return [_parseListLine(line) for line in output]


def _isRoot(directory):
  """Check if a given directory represents the root of a btrfs file system."""
  output = executeAndRead(*show(directory))
  output = output.decode("utf-8")[:-1].split("\n")

  # The output of show() contains multiple lines in case the given
  # directory is a subvolume. In case it is an ordinary directory the
  # output is a single line and begins with "ERROR:" (but the command
  # actually succeeds), and in case of the root directory it will be
  # matched here.
  return len(output) == 1 and output[0].endswith(_SHOW_IS_ROOT)


def _findRoot(directory):
  """Find the root of the btrfs file system containing the given directory."""
  assert directory

  # Note that we have no guard here against an empty directory as input
  # or later because of a dirname invocation. However, the show command
  # in _isRoot will fail for an empty directory (a case that will also
  # be hit if this function is run on a non-btrfs file system).
  while not _isRoot(directory):
    new_directory = dirname(directory)

    # Executing a dirname on the root directory ('/') just returns the
    # root directory. Guard against endless loops.
    if new_directory == directory:
      raise FileNotFoundError("Root of btrfs file system not found for "
                              "directory: \"%s\"" % directory)

    directory = new_directory

  return directory


def _snapshotBaseName(subvolume):
  """Retrieve the base name of a snapshot for the given subvolume.

    The basename is the part of the first part of a snapshot's name that
    stays constant over time (but not system), i.e., that has no time
    information encoded in it and does not depend on data variable over
    time.
  """
  r = uname()
  name = "%s-%s-%s" % (r.nodename, r.sysname.lower(), r.machine)
  path = subvolume.replace(sep, "_")
  return "%s-%s" % (name, path)


def _ensureUniqueName(snapshot, snapshots):
  """Make sure that a snapshot name is unique by potentially appending a number.

    Check if a snapshot with this name already exists in the given list.
    This can happen if we sync in very rapid succession (with data being
    added in between). In this case we need to add a number to
    snapshot's name to avoid name clashes.
  """
  i = 1
  name = snapshot

  # Note that there might be multiple snapshots created this way, so not
  # just pick the first number and be done but actually verify that the
  # newly generated name is unique and if not increment the number and
  # try again.
  # Note: Strictly speaking we would have to verify that appending a
  #       dash with a number preserves the sorting property that the
  #       most recent snapshot (in this case the one with the higher
  #       number if everything else in the name is equal) is listed
  #       last. We luck out because the time format already contains a
  #       dash as a separator so the existing test covers this case as
  #       well.
  while _findSnapshotByName(snapshots, name):
    name = "%s-%s" % (snapshot, i)
    i = i + 1

  # TODO: By just returning a name without actually creating the
  #       snapshot at the same moment we potentially race with
  #       concurrent snapshot operations. We should cope with failures
  #       due to name clashes instead.
  return name


def _snapshotName(subvolume, snapshots):
  """Retrieve a fully qualified, unique snapshot name."""
  name = _snapshotBaseName(subvolume)
  time = datetime.strftime(datetime.now(), _TIME_FORMAT)
  snapshot = "%s-%s" % (name, time)

  return _ensureUniqueName(snapshot, snapshots)


def _findSnapshotsForSubvolume(snapshots, subvolume):
  """Given a list of snapshots, find all belonging to the given subvolume."""
  base = _snapshotBaseName(subvolume)

  # It is worth pointing out that we assume here (and in a couple of
  # other locations) that all relevant snapshots are *not* located in a
  # sub-directory, otherwise we cannot simply compare the base against
  # the beginning of the string. This is a valid assumption for this
  # program, though.
  return list(filter(lambda x: x["path"].startswith(base), snapshots))


def _findMostRecent(snapshots, subvolume):
  """Given a list of snapshots, find the most recent one."""
  snapshots = _findSnapshotsForSubvolume(snapshots, subvolume)

  if not snapshots:
    return None

  # The most recent snapshot is the last since we list snapshots in
  # ascending order by date.
  return snapshots[-1]["path"]


def _findSnapshotByName(snapshots, name):
  """Check if a list of snapshots contains a given one."""
  snapshots = list(filter(lambda x: x["path"] == name, snapshots))

  if not snapshots:
    return None

  snapshot, = snapshots
  return snapshot


def _createSnapshot(subvolume, repository, snapshots):
  """Create a snapshot of the given subvolume in the given repository."""
  # TODO: We need to create an incremental snapshot here, i.e., one that
  #       only contains the changes over another snapshot. This
  #       functionality is very important to keep the amount of data
  #       transferred as low as possible which in turn allows for more
  #       frequent snapshotting to take place.
  name = _snapshotName(subvolume, snapshots)

  execute(*mkSnapshot(subvolume, repository.path(name)))
  return name


def _findOrCreate(subvolume, repository):
  """Ensure an up-to-date snapshot is available in the given repository."""
  snapshots = repository.snapshots()
  name = _findMostRecent(snapshots, subvolume)

  # If we found no snapshot or if files are changed between the current
  # state of the subvolume and the most recent snapshot we just found
  # then create a new snapshot.
  # TODO: This part is sub-optimal. We find the most recent snapshot and
  #       return its path. Now, Repository.diff again retrieves a list
  #       of all snapshots to retrieve the generation number but we
  #       already had this information available, we just discarded it.
  if not name or repository.diff(name, subvolume):
    return _createSnapshot(subvolume, repository, snapshots), True

  return name, False


def _deploy(snapshot, created, src, dst):
  """Deploy a snapshot to a repository."""
  # Only if the snapshot did exist previously can it possibly be already
  # in the destination repository.
  if not created:
    if _findSnapshotByName(dst.snapshots(), snapshot):
      # The snapshot is already present in the repository. There is
      # nothing to be done.
      return

  # Be sure to have the snapshot persisted to disk before trying to
  # serialize it.
  execute(*syncFs(src.root))
  # Finally transfer the snapshot from the source repository to the
  # destination.
  pipeline([
    serialize(src.path(snapshot)),
    deserialize(dst.path())
  ])


def _sync(subvolume, src, dst):
  """Sync a single subvolume between two repositories.

    The synchronization of two repositories is a two step process:
    1) Snapshot creation.
      o Find most recent snapshot in source repository for the subvolume
      | to backup.
      |-> Found one:
      |   o Check if the subvolume to backup has file changes with
      |   | respect to this snapshot.
      |   |-> Yes:
      |   |   o Create a new snapshot.
      |   |-> No:
      |       o Our snapshot is up-to-date, no need to create a new one.
      |-> Found none:
          o Create a new snapshot.
    2) Snapshot deployment.
      o Check whether the most recent snapshot (there now has to be one)
      | is available in the destination repository.
      |-> Yes:
      |   o The source and destination repositories are in sync already.
      |-> No:
          o Transfer the snapshot to the destination repository.
  """
  snapshot, created = _findOrCreate(subvolume, src)
  _deploy(snapshot, created, src, dst)


def sync(subvolumes, src, dst):
  """Sync the given subvolumes between two repositories, i.e., this one and a "remote" one."""
  for subvolume in subvolumes:
    _sync(subvolume, src, dst)


def _trail(path):
  """Ensure the path has a trailing separator."""
  return join(path, "")


class Repository:
  """This class represents a repository for snapshots."""
  def __init__(self, directory):
    """Initialize the object and bind it to the given directory."""
    self._root = _findRoot(directory)
    self._directory = _trail(directory)


  def snapshots(self):
    """Retrieve a list of snapshots in this repository.

      TODO: It seems likely this function is invoked from multiple
            places because its output has some significance. Given this
            suspicion, it might make sense to cache its output. Caching
            would introduce an additional constraint in that we would
            not detect newly created snapshots (not created by
            ourselves) but it seems to be reasonable to assume we are
            the only ones creating snapshots (of interest for this
            program, i.e., following a particular naming scheme to be
            decided) in the given repository.
    """
    snapshots = _snapshots(self._directory)

    # We need to work around the btrfs problem that not necessarily all
    # snapshots listed are located in our repository's directory.
    with alias(self._directory) as prefix:
      # We only want to loop once but we need to remove items during
      # iteration. So we iterate over a *copy* while deleting from the
      # original. In order to ensure all indices are valid even in the
      # face of deletion, we need to iterate from back to front. The
      # enumerate function counts in ascending order so for the deletion
      # we need to subtract the index from the length of the original
      # array but because of reverse iteration we need to subtract one
      # more.
      rlen = len(snapshots) - 1
      copy = snapshots.copy()

      for i, snapshot in enumerate(reversed(copy)):
        # Make all paths absolute.
        path = join(self._root, snapshot["path"])
        # Check if the snapshot is not located in this repository's
        # directory.
        if path.startswith(prefix):
          # Valid snapshot. Remove the now common prefix.
          snapshot["path"] = path[len(prefix):]
        else:
          # Snapshot not in our directory. Remove it from the list.
          del snapshots[rlen - i]

      # TODO: We currently return a list of snapshots in the internally
      #       used format, i.e., a dict that contains a 'path' and a
      #       'gen' key. Clients should not require the latter
      #       information and, thus, only the paths should be exposed to
      #       the outside. Such a change might require some adjustments,
      #       however, and it is unclear whether it is worth the effort.
      return snapshots


  def diff(self, snapshot, subvolume):
    """Find the files that changed in a given subvolume with respect to a snapshot."""
    # We are given a snapshot but we need to know its generation ID. So
    # retrieve the list of available snapshots and find the given one. A
    # nice side effect is that we check the validity of the snapshot
    # being passed in.
    found = _findSnapshotByName(self.snapshots(), snapshot)
    if not found:
      raise FileNotFoundError("Snapshot not found: \"%s\"" % snapshot)

    # TODO: Strictly speaking the command created by diff() works on a
    #       generation basis and has no knowledge of snapshots. We need
    #       to clarify whether a new snapshot *always* also means a new
    #       generation (I assume so, but it would be best to get
    #       confirmation).
    output = executeAndRead(*diff(subvolume, found["gen"]))
    output = output.decode("utf-8")[:-1].split("\n")
    # The diff output usually is ended by a line such as:
    # "transid marker was" followed by a generation ID. We should ignore
    # those lines since we do not require this information. So filter
    # them out here.
    output = filter(lambda x: not x.startswith(_DIFF_IGNORE), output)
    return [_parseDiffLine(line) for line in output]


  def path(self, *components):
    """Form an absolute path by combining the given path components."""
    return join(self._directory, *components)


  @property
  def root(self):
    """Retrieve the root directory of the btrfs file system the repository resides on."""
    return self._root
